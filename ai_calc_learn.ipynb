{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_calc_learn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LCeMlarhclUK",
        "A97vg8Tm2UeZ",
        "Af1MtjVWV4Vw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isao1974/ai_calc/blob/master/ai_calc_learn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCeMlarhclUK",
        "colab_type": "text"
      },
      "source": [
        "# 準備\n",
        "csvファイルからデータを読み込み学習させる。\n",
        "\n",
        "csvファイルはgdrive上に用意するためgdriveをマウントする。\n",
        "colaboratory 上でのCSVファイルの読み込みは下記を参照\n",
        "https://qiita.com/uni-3/items/201aaa2708260cc790b8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lZ4JKh1bgdQ",
        "colab_type": "code",
        "outputId": "5b3a0ae5-7db8-4f05-8e9f-497a2fb77f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmGFLorAFyzX",
        "colab_type": "text"
      },
      "source": [
        "コマンド\n",
        "!ls など、!を頭につけると、コマンドが実行できる。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQhzx3PXDSIz",
        "colab_type": "code",
        "outputId": "e3da6317-e2c8-4b52-e88c-aee3fd61b9ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "!conda list\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: conda: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU9Rs2X32RTN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A97vg8Tm2UeZ",
        "colab_type": "text"
      },
      "source": [
        "# 学習用データ作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA7ouKHF2ZYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import csv\n",
        "import pdb\n",
        "import os\n",
        "import sys\n",
        "#pdb.set_trace()\n",
        "\n",
        "home_dir = \"drive/My Drive/Colab Notebooks/data/\"\n",
        "if os.path.isdir(home_dir) == False:\n",
        "  print(\"file not found:\" + home_dir)\n",
        "  sys.exit()\n",
        "    \n",
        "# 加算データ\n",
        "data_file = home_dir + \"addData.csv\"\n",
        "with open(data_file, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['ope', '1st', '2nd', 'ans'])\n",
        "\n",
        "  num = 0\n",
        "  while num < 1000:\n",
        "    val0 = 1\n",
        "    val1 = random.randint(-100, 100)\n",
        "    val2 = random.randint(-100, 100)\n",
        "    val3 = val1 + val2\n",
        "    writer.writerow([val0, val1, val2, val3])\n",
        "    num += 1\n",
        "\n",
        "#減算データ   \n",
        "data_file = home_dir + \"subData.csv\"\n",
        "with open(data_file, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['ope', '1st', '2nd', 'ans'])\n",
        "    \n",
        "  num = 0\n",
        "  while num < 1000:\n",
        "    val0 = 2\n",
        "    val1 = random.randint(-100, 100)\n",
        "    val2 = random.randint(-100, 100)\n",
        "    val3 = val1 - val2\n",
        "    writer.writerow([val0, val1, val2, val3])\n",
        "    num += 1\n",
        "\n",
        "#乗算データ    \n",
        "data_file = home_dir + \"mulData.csv\"\n",
        "with open(data_file, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['ope', '1st', '2nd', 'ans'])\n",
        "    \n",
        "  num = 0\n",
        "  while num < 1000:\n",
        "    val0 = 3\n",
        "    val1 = random.randint(-100, 100)\n",
        "    val2 = random.randint(-100, 100)\n",
        "    val3 = val1 * val2\n",
        "    writer.writerow([val0, val1, val2, val3])\n",
        "    num += 1\n",
        "\n",
        "\n",
        "#除算データ\n",
        "data_file = home_dir + \"devData.csv\"\n",
        "with open(data_file, 'w') as f:\n",
        "  writer = csv.writer(f)\n",
        "  writer.writerow(['ope', '1st', '2nd', 'ans'])\n",
        "    \n",
        "  num = 0\n",
        "  while num < 1000:\n",
        "    val0 = 4\n",
        "    val1 = random.randint(-100, 100)\n",
        "    val2 = random.randint(-100, 100)\n",
        "    if val2 == 0:\n",
        "      continue\n",
        "    else:\n",
        "      val3 = round(val1 / val2, 1)\n",
        "    writer.writerow([val0, val1, val2, val3])\n",
        "    num += 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af1MtjVWV4Vw",
        "colab_type": "text"
      },
      "source": [
        "# 機械学習\n",
        "\n",
        "学習済みモデルを使用する。\n",
        "*   ph1: 加算する学習モデルを作成\n",
        "*   ph2:四則演算する学習モデルを作成\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhX4v7sXiZA6",
        "colab_type": "text"
      },
      "source": [
        "https://qiita.com/Sa2Knight/items/221be46f2702ae453ba9\n",
        "を参考に足し算を学習する学習モデルを作成する\n",
        "モデルは保存する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzj5takscaBD",
        "colab_type": "text"
      },
      "source": [
        "加算学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Eq19HairsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame\n",
        "from sklearn import linear_model\n",
        "import pickle\n",
        "\n",
        "formulas = DataFrame([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [0, 2],\n",
        "    [1, 0],\n",
        "    [1, 1],\n",
        "    [1, 2],\n",
        "    [2, 0],\n",
        "    [2, 1],\n",
        "    [2, 2]\n",
        "])\n",
        "answers = DataFrame([0, 1, 2, 1, 2, 3, 2, 3, 4])\n",
        "\n",
        "model = linear_model.LinearRegression()\n",
        "model.fit(formulas, answers)\n",
        "\n",
        "with open('model.pickle', mode='wb') as fp:\n",
        "  pickle.dump(model, fp)\n",
        "  \n",
        "\n",
        "while True:\n",
        "     # 標準入力から計算式を取得\n",
        "     print('> ', end='')\n",
        "     inStr = input()\n",
        "    \n",
        "     if inStr == 'q':\n",
        "      break\n",
        "        \n",
        "     x, y = list(map(lambda x: int(x), inStr.split(' ')))\n",
        "\n",
        "     # 学習モデルを用いて回答を取得し、標準出力\n",
        "     predected_answer = model.predict([[x, y]])\n",
        "     print(\"{0} + {1} = {2}\".format(x, y, int(predected_answer[0][0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH80unXnPSmH",
        "colab_type": "text"
      },
      "source": [
        "保存したモデルを使う"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH8FpBCAn9xB",
        "colab_type": "text"
      },
      "source": [
        "DataFrame の１番目を演算子として学習モデルを作る。\n",
        "linear_model.LinearRegression だと期待する結果が得られなかったので、\n",
        "様々な識別器を試してみる。\n",
        "\n",
        "識別器一覧\n",
        "https://qiita.com/yhyhyhjp/items/3ca101f1cb5dee310c06\n",
        "\n",
        "結果は失敗。\n",
        "原因推測\n",
        "* 学習データが少ない？\n",
        "* モデルのハイパーパラメータが調整できてない？\n",
        "* 機械学習では無理？ディープラーニングだといける？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoTQI5QAPU1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame\n",
        "from sklearn import linear_model\n",
        "import pickle\n",
        "\n",
        "with open('model.pickle', mode='rb') as fp:\n",
        "  model = pickle.load(fp)\n",
        "  \n",
        "  # 加算\n",
        "  x, y = 10, 20\n",
        "  predected_answer = model.predict([[x, y]])\n",
        "  print(\"{0} + {1} = {3}\".format(x, y, z, int(predected_answer[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y5JiL07-Am5",
        "colab_type": "text"
      },
      "source": [
        "csv ファイルからデータ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVYZKtcBcKog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from sklearn import linear_model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "h = .02  # step size in the mesh\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"linear\", C=0.025),\n",
        "    SVC(gamma=2, C=1),\n",
        "    DecisionTreeClassifier(max_depth=5),\n",
        "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "\n",
        "# test file existence\n",
        "testDataFile = \"drive/My Drive/Colab Notebooks/data.csv\"\n",
        "if os.path.isfile(testDataFile) == False:\n",
        "  print(\"file not found\")\n",
        "  sys.exit()\n",
        "  \n",
        "\n",
        "# read file and split data\n",
        "data = pd.read_csv(testDataFile, header=0)\n",
        "X = data.loc[:, ['ope', '1st', '2nd']]\n",
        "Y = data.loc[:, ['ans']]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
        "\n",
        "\n",
        "#learning\n",
        "for model in classifiers:\n",
        "  print(model.__class__.__name__)  \n",
        "  filename = \"drive/My Drive/Colab Notebooks/\"\n",
        "  filename += model.__class__.__name__\n",
        "  filename += \".pickle\"\n",
        "  print(filename)\n",
        "  model.fit(X_train, Y_train)\n",
        "  print(model.score(X_test, Y_test))\n",
        "  print(\"-------\")\n",
        "  \n",
        "  with open(filename, mode='wb') as fp:\n",
        "    pickle.dump(model, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGamz-MCC5oI",
        "colab_type": "text"
      },
      "source": [
        "学習モデルを使って推論\n",
        "90%のスコアのSVCで推論させたが、数値が小さいときはいいけど、2桁になるともうダメ。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAf3ZCeXC8fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas import DataFrame\n",
        "from sklearn import linear_model\n",
        "import pickle\n",
        "\n",
        "filename = \"drive/My Drive/Colab Notebooks/\"\n",
        "filename += \"SVC\"\n",
        "filename += \".pickle\"\n",
        "\n",
        "\n",
        "with open(filename, mode='rb') as fp:\n",
        "  model = pickle.load(fp)\n",
        "  \n",
        "  # 加算\n",
        "  ope, x, y = 0, 100, 200\n",
        "  predected_answer = model.predict([[ope, x, y]])\n",
        "  print(\"{0} ,{1}, {2} = {3}\".format(ope, x, y, int(predected_answer[0])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOkZWQyeCmfb",
        "colab_type": "text"
      },
      "source": [
        "# deep learning で学習\n",
        "* ph1: 加算する学習モデルを作成\n",
        "* ph2:四則演算する学習モデルを作成\n",
        "\n",
        "注意点\n",
        "* 出力の活性化関数は linearを使う\n",
        "* 損失関数は 二乗誤差を使う。交差エントロピーは確率で使うのでダメ。\n",
        "\n",
        "四則演算を別々に学習\n",
        "https://qiita.com/aidy91614/items/e90ee45fb82c1724d654\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qGJYHiwCpxU",
        "colab_type": "code",
        "outputId": "6e55fa6b-def2-4eb5-b489-1a61ae85701c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def leaning(testDataFile, orgModel, epoch, modelFile):\n",
        "  # test file existence\n",
        "  if os.path.isfile(testDataFile) == False:\n",
        "    print(\"file not found:\" + testDataFile)\n",
        "    sys.exit()\n",
        "\n",
        "  config = orgModel.get_config()\n",
        "  model = Sequential.from_config(config)\n",
        "  # read file and split data\n",
        "  data = pd.read_csv(testDataFile, header=0)\n",
        "  X = data.loc[:, ['ope', '1st', '2nd']]\n",
        "  Y = data.loc[:, ['ans']]\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['accuracy'])\n",
        "  model.fit(X_train, Y_train, epochs=epoch, batch_size=64, verbose=0)\n",
        "  score = model.evaluate(X_test, Y_test)\n",
        "  print(\"loss=%f, acc=%f\" % (score[0], score[1]))\n",
        "  \n",
        "  # save model\n",
        "  with open(modelFile, mode='wb') as fp:\n",
        "    pickle.dump(model, fp)\n",
        "\n",
        "    \n",
        "home_dir =  \"drive/My Drive/Colab Notebooks/\"\n",
        "\n",
        "# construct model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=3))\n",
        "model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "plot_model(model, to_file=home_dir + \"model/DL_Model.png\", show_shapes=True)\n",
        "model.compile(loss='mean_squared_error', optimizer='Adam', metrics=['accuracy'])\n",
        "\n",
        "leaning(home_dir + \"data/devData.csv\", model, 2000, home_dir + \"model/devModel.pickle\")\n",
        "leaning(home_dir + \"data/mulData.csv\", model, 2000, home_dir + \"model/mulModel.pickle\")\n",
        "leaning(home_dir + \"data/addData.csv\", model, 2000, home_dir + \"model/addModel.pickle\")\n",
        "leaning(home_dir + \"data/subData.csv\", model, 2000, home_dir + \"model/subModel.pickle\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 04:57:02.451878 139809719236480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 04:57:02.466619 139809719236480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 04:57:02.469204 139809719236480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 04:57:02.584430 139809719236480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 04:57:02.796923 139809719236480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0726 04:57:02.904707 139809719236480 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 0s 275us/step\n",
            "loss=31.024055, acc=0.115000\n",
            "200/200 [==============================] - 0s 308us/step\n",
            "loss=2865.266172, acc=0.000000\n",
            "200/200 [==============================] - 0s 448us/step\n",
            "loss=0.031020, acc=1.000000\n",
            "200/200 [==============================] - 0s 534us/step\n",
            "loss=0.005238, acc=1.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq55NZcDrc1s",
        "colab_type": "text"
      },
      "source": [
        "deep learning の学習モデルを使って推論する\n",
        "\n",
        "python での四捨五入\n",
        "https://note.nkmk.me/python-round-decimal-quantize/\n",
        "\n",
        "フォーマット\n",
        "https://www.headboost.jp/python-how-to-handle-digits/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5ATamfzkI1y",
        "colab_type": "code",
        "outputId": "af8b2618-5f13-4572-e852-6eacef41c13a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import plot_model\n",
        "from pandas import DataFrame\n",
        "import pickle\n",
        "import numpy as np\n",
        "from decimal import Decimal, ROUND_HALF_UP, ROUND_HALF_EVEN\n",
        "\n",
        "#load models\n",
        "home_dir = \"drive/My Drive/Colab Notebooks/model/\"\n",
        "\n",
        "addFp = open(home_dir + \"addModel.pickle\", mode='rb')\n",
        "addModel = pickle.load(addFp)\n",
        "\n",
        "subFp = open(home_dir + \"subModel.pickle\", mode='rb')\n",
        "subModel = pickle.load(subFp)\n",
        "\n",
        "mulFp = open(home_dir + \"mulModel.pickle\", mode='rb')\n",
        "mulModel = pickle.load(mulFp)\n",
        "\n",
        "devFp = open(home_dir + \"devModel.pickle\", mode='rb')\n",
        "devModel = pickle.load(devFp)\n",
        "\n",
        "while True:\n",
        "  # 標準入力から計算式を取得\n",
        "  print('> ', end='')\n",
        "  inStr = input()\n",
        "\n",
        "  if inStr == 'q':\n",
        "    print(\"exit\")\n",
        "    break\n",
        "\n",
        "  ope, x, y = list(map(lambda x: int(x), inStr.split(' ')))\n",
        "\n",
        "  # 学習モデルを用いて回答を取得し、標準出力\n",
        "  if ope == 1:\n",
        "    predected_answer = addModel.predict(np.array([[ope, x, y]]))\n",
        "    print(\"{0} + {1} = {2}\".format(x, y, int(predected_answer[0])))\n",
        "  elif ope == 2:\n",
        "    predected_answer = subModel.predict(np.array([[ope, x, y]]))\n",
        "    print(\"{0} - {1} = {2}\".format(x, y, int(predected_answer[0])))\n",
        "  elif ope == 3:\n",
        "    predected_answer = mulModel.predict(np.array([[ope, x, y]]))\n",
        "    print(\"{0} * {1} = {2}\".format(x, y, int(predected_answer[0])))\n",
        "  elif ope == 4:\n",
        "    predected_answer = devModel.predict(np.array([[ope, x, y]]))\n",
        "    print(\"{0} / {1} = {2}\".format(x, y, int(predected_answer[0])))\n",
        "  else:\n",
        "    print(\"unknown operater:{0}\".format(ope))\n",
        "\n",
        "      \n",
        "addFp.close()\n",
        "subFp.close()\n",
        "mulFp.close()\n",
        "devFp.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 05:30:17.670423 139927840696192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 05:30:17.688233 139927840696192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 05:30:17.750643 139927840696192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0726 05:30:17.751746 139927840696192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0726 05:30:17.752685 139927840696192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0726 05:30:18.579997 139927840696192 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 1 2 3\n",
            "2 + 3 = 5\n",
            "> 1 5 5\n",
            "5 + 5 = 10\n",
            "> 1 10 10\n",
            "10 + 10 = 20\n",
            "> 1 200 10\n",
            "200 + 10 = 210\n",
            "> 2 300 10\n",
            "300 - 10 = 290\n",
            "> 2 400 20\n",
            "400 - 20 = 380\n",
            "> 3 10 10\n",
            "10 * 10 = 87\n",
            "> 3 10 200\n",
            "10 * 200 = 1116\n",
            "> 4 6 3\n",
            "6 / 3 = 1\n",
            "> "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}